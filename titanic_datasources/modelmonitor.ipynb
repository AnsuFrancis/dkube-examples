{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "import os,json, time, operator\n",
    "from dkube.sdk import *\n",
    "from dkube.sdk.api import DkubeApi\n",
    "from dkube.sdk.rsrcs import DkubeModelmonitor\n",
    "from dkube.sdk.rsrcs.modelmonitor import DatasetClass,ModelType,DriftAlgo, TimeZone\n",
    "from dkube.sdk.rsrcs.modelmonitor import DatasetFormat,DkubeModelmonitorAlert, DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONITOR_NAME = titanic_d3_config['MONITOR_NAME']\n",
    "DATA_SOURCE = titanic_d3_config['DATA_SOURCE']\n",
    "INPUT_TRAIN_TYPE = titanic_d3_config['INPUT_TRAIN_TYPE']\n",
    "DKUBEUSERNAME = titanic_d3_config['DKUBEUSERNAME']\n",
    "TOKEN = titanic_d3_config['TOKEN']\n",
    "DKUBE_URL = titanic_d3_config['DKUBE_URL']\n",
    "DKUBE_BASE_DATASET = titanic_d3_config['DKUBE_BASE_DATASET']\n",
    "MODEL_NAME = titanic_d3_config['MODEL_NAME']\n",
    "RETRAINING_DATASET = titanic_d3_config['RETRAINING_DATASET']\n",
    "RUN_FREQUENCY = titanic_d3_config['RUN_FREQUENCY']\n",
    "USE_REMOTE_DEPLOYMENT = titanic_d3_config[\"USE_REMOTE_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DkubeApi(URL=os.getenv('DKUBE_URL',DKUBE_URL),token=os.getenv(\"DKUBE_USER_ACCESS_TOKEN\",TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_deployment_running(deployment_id):\n",
    "    status = None\n",
    "    inference_url, inference = None, None\n",
    "    while True:\n",
    "        data = api.get_deployment(deployment_id)\n",
    "        status = data.data.inferenceservice_deployment.parameters.generated.status.state\n",
    "        inference = data.data.inferenceservice_deployment.parameters.inference\n",
    "        inference_url = data.data.inferenceservice_deployment.parameters.generated.details.serving.servingurl\n",
    "        if status == \"RUNNING\":\n",
    "            break\n",
    "        print(\"waiting for deployment to be running\")\n",
    "        time.sleep(api.wait_interval)\n",
    "    return inference, inference_url\n",
    "\n",
    "def get_dataset_version(username, dataset_name, version):\n",
    "    dataset_versions = api.get_dataset_versions(username, dataset_name)\n",
    "    versions = []\n",
    "    for each_version in dataset_versions:\n",
    "        if each_version[\"version\"][\"name\"] == version:\n",
    "            uuid = each_version[\"version\"][\"uuid\"]\n",
    "            return f\"{version}:{uuid}\"\n",
    "        else:\n",
    "            versions.append(each_version[\"version\"][\"name\"])\n",
    "    return f\"dataset version {version} not found, available version are {versions}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REMOTE_DEPLOYMENT:\n",
    "    api.import_deployment(name=MONITOR_NAME)\n",
    "while True:\n",
    "    DEPLOYMENT_ID = api.get_deployment_id(name=MONITOR_NAME)\n",
    "    if DEPLOYMENT_ID:\n",
    "        break\n",
    "    print(\"waiting for deployment to come up\")\n",
    "    time.sleep(api.wait_interval)\n",
    "if not USE_REMOTE_DEPLOYMENT:\n",
    "    inference, INFERENCE_URL = wait_for_deployment_running(DEPLOYMENT_ID)\n",
    "    print(\"Inference is up at URL: \", INFERENCE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"transform_data.py\", \"r\")\n",
    "#read whole file to a string\n",
    "script = text_file.read()\n",
    "#close file\n",
    "text_file.close()\n",
    "\n",
    "with open('thresholds.json') as f:\n",
    "    thresholds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=DkubeModelmonitor(deployemnt_id = DEPLOYMENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.update_modelmonitor_basics(model_type=ModelType.Classification.value, \n",
    "                               input_data_type=DataType.Tabular.value,\n",
    "                               data_timezone=TimeZone.UTC.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.add_thresholds(thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if imported cluster has cluster added \n",
    "# Or is it a local deployemnt.\n",
    "deployment = api.get_deployment(DEPLOYMENT_ID)\n",
    "if ((deployment.data.imported_deployment and deployment.data.imported_deployment.cluster)\n",
    "    or\n",
    "    not deployment.data.imported_deployment):\n",
    "    mm.update_deployment_monitoring_details(enabled=True, frequency=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Drift monitoring details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.update_drift_monitoring_details(enabled=True,frequency=5,algorithm='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"local\" or DATA_SOURCE == \"aws-s3\":\n",
    "    training_data = f'{DKUBEUSERNAME}:{DKUBE_BASE_DATASET}'\n",
    "    train_data_version = 'v1:'+api.get_dataset_versions(\n",
    "        DKUBEUSERNAME,\n",
    "        DKUBE_BASE_DATASET)[0]['version']['uuid']\n",
    "    prediction_data = f\"{DKUBEUSERNAME}:{MONITOR_NAME}-predict\"\n",
    "    labelled_data = f\"{DKUBEUSERNAME}:{MONITOR_NAME}-groundtruth\"\n",
    "\n",
    "if DATA_SOURCE == 'local':\n",
    "    predict_data_version = 'v1:'+api.get_dataset_versions(\n",
    "        DKUBEUSERNAME,\n",
    "        MONITOR_NAME+'-predict')[0]['version']['uuid']\n",
    "    labelled_data_version = 'v1:'+api.get_dataset_versions(\n",
    "        DKUBEUSERNAME,\n",
    "        MONITOR_NAME+'-groundtruth')[0]['version']['uuid']\n",
    "\n",
    "predict_data_format = str(DatasetFormat.Tabular)\n",
    "\n",
    "if DATA_SOURCE == \"sql\":\n",
    "    training_data = f'{DKUBEUSERNAME}:{DKUBE_BASE_DATASET}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == 'sql':\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Train),name=training_data,data_format=str(DatasetFormat.Tabular),sql_query=\"select * from titanic\",transformer_script = script)\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Predict),name=training_data,data_format=str(DatasetFormat.Tabular),sql_query=\"select * from titanic_predict\",date_suffix=\"yyyy/mm/dd/hh\")\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Labelled),name=training_data,data_format=str(DatasetFormat.Tabular),sql_query=\"select * from titanic_gt\",predict_col=\"Survived\",groundtruth_col=\"GT_target\",timestamp_col=\"timestamp\")\n",
    "\n",
    "if DATA_SOURCE == 'local':\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Train),name=training_data,data_format=str(DatasetFormat.Tabular),version=train_data_version,transformer_script = script)\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Predict),name=prediction_data,data_format=str(DatasetFormat.Tabular),version=predict_data_version,date_suffix=\"none\")\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Labelled),name=labelled_data,data_format=str(DatasetFormat.Tabular),version=labelled_data_version,predict_col=\"Survived\",groundtruth_col=\"GT_target\",timestamp_col=\"timestamp\")\n",
    "\n",
    "if DATA_SOURCE == 'aws-s3':\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Train),name=training_data,data_format=str(DatasetFormat.Tabular),version=train_data_version,transformer_script = script)\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Predict),name=prediction_data,data_format=predict_data_format,date_suffix=\"yyyy/mm/dd/hh\")\n",
    "    mm.add_datasources(data_class=str(DatasetClass.Labelled),name=labelled_data,data_format=str(DatasetFormat.Tabular),predict_col=\"Survived\",groundtruth_col=\"GT_target\",timestamp_col=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Performacne monitoring details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.update_performance_monitoring_details(enabled=True,source_type=\"labelled_data\",frequency=RUN_FREQUENCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.modelmonitor_create(mm,wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting ID of the model monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below can be used to fetch model monitor ID by name.\n",
    "# The monitor id will be same as deployment id.\n",
    "# id = api.modelmonitor_get_id(MONITOR_NAME)\n",
    "id = DEPLOYMENT_ID\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.modelmonitor_update_schema(id,label='Survived',schema_class='categorical',schema_type=\"prediction_output\")\n",
    "api.modelmonitor_update_schema(id,label='PassengerId',schema_class='continuous',schema_type=\"row_id\")\n",
    "api.modelmonitor_update_schema(id,label='timestamp',schema_class='continuous',schema_type=\"timestamp\")\n",
    "\n",
    "api.modelmonitor_update_schema(id,label='Age',schema_class='continuous',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='Fare',schema_class='continuous',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='SibSp',schema_class='continuous',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='Parch',schema_class='continuous',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='Pclass',schema_class='categorical',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='Sex_male',schema_class='categorical',schema_type='input_feature', selected=True)\n",
    "api.modelmonitor_update_schema(id,label='Sex_female',schema_class='categorical',schema_type='input_feature', selected=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment Health Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((deployment.data.imported_deployment and deployment.data.imported_deployment.cluster)\n",
    "    or\n",
    "    not deployment.data.imported_deployment):\n",
    "    alert = DkubeModelmonitorAlert(name='latency_alert', alert_class = 'deployment_health')\n",
    "    alert.add_alert_condition(metric='latency_avg',threshold=300, op=operator.gt)\n",
    "    api.modelmonitor_add_alert(id,alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert = DkubeModelmonitorAlert(name='age_alert', alert_class = 'feature_drift')\n",
    "alert.add_alert_condition(feature='Age',threshold=0.22, op=operator.gt)\n",
    "api.modelmonitor_add_alert(id,alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performacne Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert = DkubeModelmonitorAlert(name='accuracy_alert', alert_class = 'performance_decay')\n",
    "alert.add_alert_condition(metric='accuracy',threshold=0.9, op=operator.lt)\n",
    "api.modelmonitor_add_alert(id,alert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Model Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.modelmonitor_start(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "id = api.modelmonitor_get_id(MONITOR_NAME)\n",
    "\n",
    "if INPUT_TRAIN_TYPE == 'retraining':\n",
    "    api.modelmonitor_stop(id)\n",
    "    \n",
    "    training_data = f'{RETRAINING_DATASET}:'+DKUBEUSERNAME\n",
    "    data_dict = api.get_dataset_versions(DKUBEUSERNAME,RETRAINING_DATASET)[0]['version']\n",
    "    train_data_version = data_dict['name']+\":\"+data_dict['uuid']\n",
    "    \n",
    "    mm=DkubeModelmonitor(name=MONITOR_NAME)\n",
    "    mm.update_datasources(name=training_data,data_class=str(DatasetClass.Train),version=train_data_version)\n",
    "    api.modelmonitor_update(id,mm)\n",
    "    \n",
    "    \n",
    "    ### Start the model monitor\n",
    "    api.modelmonitor_start(id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP = False\n",
    "if CLEANUP:\n",
    "    from time import sleep\n",
    "    RETRIES = 4\n",
    "    while RETRIES:\n",
    "        mm = api.modelmonitor_get(id)\n",
    "        if mm[\"status\"] and mm[\"status\"][\"state\"].lower() != \"active\":\n",
    "            break\n",
    "        elif mm[\"status\"] and mm[\"status\"][\"state\"].lower() == \"active\":\n",
    "            api.modelmonitor_stop(id)\n",
    "        RETRIES -= 1\n",
    "        sleep(5)\n",
    "    else:\n",
    "        raise TimeoutError(\"modelmonitor failed to stopped\")\n",
    "    api.modelmonitor_delete(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
