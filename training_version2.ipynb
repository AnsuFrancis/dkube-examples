{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"v2_deltalake.ini\")\n",
    "\n",
    "if config[\"DEFAULT\"][\"TABLE_SOURCE\"] == \"hostpath\":\n",
    "    prefix = config[\"DEFAULT\"][\"TABLE_PATH\"]\n",
    "    user_homedir = os.getenv(\"DKUBE_USER_STORE\")\n",
    "    path = f'{user_homedir}/{prefix}'\n",
    "    version = int(config[\"DEFAULT\"][\"TABLE_VERSION\"])\n",
    "\n",
    "    dt = DeltaTable(path)\n",
    "elif config[\"DEFAULT\"][\"TABLE_SOURCE\"] == \"s3\":\n",
    "    prefix = config[\"DEFAULT\"][\"TABLE_PATH\"]\n",
    "    region = config[\"DEFAULT\"][\"AWS_REGION\"]\n",
    "    access_key = config[\"DEFAULT\"].get(\"AWS_ACCESS_KEY_ID\", \"\")\n",
    "    access_secret = config[\"DEFAULT\"].get(\"AWS_SECRET_ACCESS_KEY\", \"\")\n",
    "    version = int(config[\"DEFAULT\"][\"TABLE_VERSION\"])\n",
    "\n",
    "    if access_secret != \"\":\n",
    "        storage_options = {\"AWS_ACCESS_KEY_ID\": access_key, \"AWS_SECRET_ACCESS_KEY\": access_secret, \"AWS_REGION\": region}\n",
    "        dt = DeltaTable(f's3://{prefix}', storage_options=storage_options)\n",
    "    else:\n",
    "        #May be the role or ~/.aws/credentials is set\n",
    "        storage_options = {\"AWS_REGION\": region}\n",
    "        dt = DeltaTable(f's3://{prefix}', storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.load_version(version)\n",
    "print(\"Loaded verion => \", dt.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = dt.to_pandas()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "\n",
    "df_clean['term'] = label.fit_transform(df_clean['term'])\n",
    "df_clean['grade'] = label.fit_transform(df_clean['grade'])\n",
    "# df_clean['emp_length'] = label.fit_transform(df_clean['emp_length'])\n",
    "df_clean['home_ownership'] = label.fit_transform(df_clean['home_ownership'])\n",
    "df_clean['verification_status'] = label.fit_transform(df_clean['verification_status'])\n",
    "df_clean['pymnt_plan'] = label.fit_transform(df_clean['pymnt_plan'])\n",
    "df_clean['purpose'] = label.fit_transform(df_clean['purpose'])\n",
    "df_clean['initial_list_status'] = label.fit_transform(df_clean['initial_list_status'])\n",
    "df_clean['application_type'] = label.fit_transform(df_clean['application_type'])\n",
    "df_clean['int_rate'] = label.fit_transform(df_clean['int_rate'])\n",
    "df_clean['total_pymnt'] = label.fit_transform(df_clean['total_pymnt'])\n",
    "df_clean['total_pymnt_inv'] = label.fit_transform(df_clean['total_pymnt_inv'])\n",
    "df_clean['total_rec_prncp'] = label.fit_transform(df_clean['total_rec_prncp'])\n",
    "df_clean['recoveries']= label.fit_transform(df_clean['recoveries'])\n",
    "df_clean['collection_recovery_fee']= label.fit_transform(df_clean['collection_recovery_fee'])\n",
    "df_clean['last_pymnt_amnt']= label.fit_transform(df_clean['last_pymnt_amnt'])\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_clean.drop(['loan_status'], axis=1)\n",
    "y = df_clean['loan_status']\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, roc_curve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import numpy as np \n",
    "import mlflow.sklearn\n",
    "import urllib3\n",
    "import json\n",
    "import time\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coltrans = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0,1,2,3,4,5,6,7,8])],        \n",
    "    remainder = 'passthrough'                               \n",
    ")\n",
    "xtr, xts, ytr, yts = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size = .2,\n",
    ")\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"dl-loan\") as run:\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(xtr, ytr)\n",
    "\n",
    "    mlflow.sklearn.log_model(model, \"badloan-classifier\")\n",
    "\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    print('The training took {:.2f} seconds.'.format(duration))\n",
    "    print(\"Accuracy =>\", round(model.score(xts, yts) * 100, 2), '%')\n",
    "\n",
    "    y_pred = model.predict(xts)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(yts, y_pred)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                   display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    #plt.savefig('cm.png')\n",
    "    disp.figure_.savefig('cm.png')\n",
    "    plt.clf();plt.cla()\n",
    "    pd.crosstab(yts, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "    target_names = ['Bad Loan', 'Good Loan']\n",
    "    class_report = classification_report(yts, model.predict(xts), target_names=target_names)\n",
    "    print(class_report)\n",
    "\n",
    "\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probs = model.predict_proba(xts)\n",
    "    preds = probs[:,1]\n",
    "\n",
    "    fpr, tpr, threshold = metrics.roc_curve(yts, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # Plotting the ROC curve\n",
    "    fig1 = plt.gcf()\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    fig1.savefig('roc.png')\n",
    "    \n",
    "    acc = accuracy_score(yts, y_pred)\n",
    "    precision = precision_score(yts, y_pred)\n",
    "    roc = metrics.roc_auc_score(yts, y_pred)\n",
    "    # confusion matrix values\n",
    "    tp = cm[0][0]\n",
    "    tn = cm[1][1]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]        \n",
    "\n",
    "    # get classification metrics\n",
    "    class_report = classification_report(yts, y_pred, output_dict=True)\n",
    "    recall_0 = class_report['0']['recall']\n",
    "    f1_score_0 = class_report['0']['f1-score']\n",
    "    recall_1 = class_report['1']['recall']\n",
    "    f1_score_1 = class_report['1']['f1-score']\n",
    "\n",
    "    # log metrics in mlflow\n",
    "    mlflow.log_metric(\"accuracy_score\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"true_positive\", tp)\n",
    "    mlflow.log_metric(\"true_negative\", tn)\n",
    "    mlflow.log_metric(\"false_positive\", fp)\n",
    "    mlflow.log_metric(\"false_negative\", fn)\n",
    "    mlflow.log_metric(\"recall_0\", recall_0)\n",
    "    mlflow.log_metric(\"f1_score_0\", f1_score_0)\n",
    "    mlflow.log_metric(\"recall_1\", recall_1)\n",
    "    mlflow.log_metric(\"f1_score_1\", f1_score_1)\n",
    "    mlflow.log_metric(\"roc\", roc)\n",
    "\n",
    "    mlflow.log_artifact('cm.png', \"confusion-matrix\")\n",
    "    mlflow.log_artifact('roc.png', \"roc-auc-plots\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
