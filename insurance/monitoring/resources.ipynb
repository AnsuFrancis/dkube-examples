{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking and upgrading the DKube SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources, sys\n",
    "try:\n",
    "    dkube_sdk_version = float(pkg_resources.get_distribution(\"dkube\").version)\n",
    "except:\n",
    "    dkube_sdk_version = 0 ## means the dkube sdk is not installed\n",
    "if dkube_sdk_version < 3.7:\n",
    "    !{sys.executable} -m pip install sudo pip install  git+https://github.com/oneconvergence/dkube.git@3.7 --user >/dev/null\n",
    "%reset -f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import time,json\n",
    "from dkube.sdk import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The monitor name will be the same as the deployment name.\n",
    "## By default, the deployment name gets picked up from the last pipeline run in this insurance example.\n",
    "## If you want to create a monitor from a different deployment, provide the deployment name here.\n",
    "MONITOR_NAME = \"\"\n",
    "\n",
    "## By default, you will be running this notebook script\n",
    "##  (1) within the setup where the deployment is executing, and\n",
    "##  (2) executing the monitor on the same cluster\n",
    "## \n",
    "## If either of these are not true (i.e. you are running the monitor on another cluster),\n",
    "## change the variable to SERVING_CLUSTER_EXECUTION = False\n",
    "## You will then need to provide input to other variables as described below\n",
    "SERVING_CLUSTER_EXECUTION = True\n",
    "\n",
    "## If \"SERVING_CLUSTER_EXECUTION = False\" then SERVING_DKUBE_URL, SERVING_DKUBE_CLUSTER_NAME, & information on the\n",
    "## monitoring cluster must be completed.\n",
    "##\n",
    "## The SERVING_DKUBE_URL is the external IP of the serving cluster (e.g. https://<External IP>:32222/)\n",
    "##  Note: The final \"/\" must be included\n",
    "SERVING_DKUBE_URL = \"\"\n",
    "\n",
    "\n",
    "MONITORING_DKUBE_URL = \"\"\n",
    "MONITORING_DKUBE_USERNAME = \"\"\n",
    "MONITORING_DKUBE_TOKEN = \"\"\n",
    "\n",
    "## Provide the existing cluster name (link) on the monitoring setup which points to the serving cluster.\n",
    "## Leave it empty if a new cluster needs to be created.\n",
    "## A new cluster will only be created if the user has operator role permission. \n",
    "SERVING_DKUBE_CLUSTER_NAME = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## If the IDE is created within a Project, then it will be picked up automatically.\n",
    "## Otherwise, the resources will not be created in a project.\n",
    "project_id = os.environ.get(\"DKUBE_PROJECT_ID\")\n",
    "\n",
    "# If the monitor is on the same cluster as the serving, pick up everything by default.\n",
    "# Otherwise, get the URL from the cell above\n",
    "if SERVING_CLUSTER_EXECUTION:\n",
    "    MINIO_ENDPOINT = os.getenv(\"MLFLOW_S3_ENDPOINT_URL\")\n",
    "    SERVING_DKUBE_URL = os.getenv(\"DKUBE_URL\")\n",
    "else:\n",
    "    parsed_url = urlparse(SERVING_DKUBE_URL)\n",
    "    SERVING_DKUBE_IP = parsed_url.hostname\n",
    "    MINIO_ENDPOINT = f\"http://{SERVING_DKUBE_IP}:32221\"\n",
    "\n",
    "if (not SERVING_DKUBE_URL) or (not MINIO_ENDPOINT):\n",
    "    raise ValueError(\"Either SERVING_DKUBE_URL or MINIO_ENDPOINT is empty\")\n",
    "\n",
    "## Assign the username & token for access to the serving cluster\n",
    "SERVING_DKUBE_USERNAME = os.getenv(\"DKUBE_USER_LOGIN_NAME\",\"\")\n",
    "SERVING_DKUBE_TOKEN = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\",\"\") \n",
    "\n",
    "## By default, the monitor name will get picked up from the deployment name created in the\n",
    "## last pipeline run in insurance example.\n",
    "## If a different deployment name is specified, it will get filled in here\n",
    "\n",
    "if MONITOR_NAME == \"\":\n",
    "    MONITOR_NAME = pl_config.get(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "# Required in train.ipynb to retrain the model\n",
    "LIVE_DATASET =  MONITOR_NAME+'-s3'\n",
    "\n",
    "## Inference URL\n",
    "INFERENCE_URL = None\n",
    "\n",
    "# dataset to be used as training data\n",
    "DKUBE_BASE_DATASET = \"insurance-data\"\n",
    "\n",
    "# Model name to be created or used for example, it will create the model\n",
    "# if not existing otherwise it will ignore creation.\n",
    "MODEL_NAME = MONITOR_NAME\n",
    "\n",
    "# the frequency with which monitoring will run, value will be considered in minutes\n",
    "RUN_FREQUENCY = 5\n",
    "\n",
    "\n",
    "# Include the project name within the tags field\n",
    "if project_id:\n",
    "    tags = [f\"project:{project_id}\"]\n",
    "else:\n",
    "    tags = []\n",
    "\n",
    "if not MODEL_NAME:\n",
    "    raise Exception(\"Model name is empty\")\n",
    "\n",
    "if not(SERVING_DKUBE_TOKEN and SERVING_DKUBE_USERNAME and SERVING_DKUBE_URL):\n",
    "    raise Exception(\"Please fill the Serving Dkube details first (SERVING_DKUBE_TOKEN, SERVING_DKUBE_URL, SERVING_DKUBE_USERNAME)\")\n",
    "    \n",
    "if (MONITORING_DKUBE_URL\n",
    "   and\n",
    "   not(MONITORING_DKUBE_USERNAME and MONITORING_DKUBE_TOKEN)):\n",
    "    raise Exception(\"Please fill the Monitoring Dkube details first (MONITORING_DKUBE_USERNAME, MONITORING_DKUBE_TOKEN, MONITORING_DKUBE_URL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dkube Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_api = DkubeApi(URL=SERVING_DKUBE_URL,token=SERVING_DKUBE_TOKEN)\n",
    "if SERVING_DKUBE_USERNAME == serving_api.validate_token()['username']:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Invalid User, please check your username, first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MONITORING_DKUBE_URL:\n",
    "    data = serving_api.get_modelmonitor_id(MONITOR_NAME)\n",
    "    if data.data:\n",
    "        MONITOR_ID = data.data.get(MONITOR_NAME)\n",
    "        if MONITOR_ID:\n",
    "            raise ValueError(f\"{MONITOR_NAME} monitor already existing please use a different name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response =  serving_api.get_cloudevents_logstore_creds()\n",
    "MINIO_KEY = response[\"access_key_id\"]\n",
    "MINIO_SECRET_KEY = response[\"access_key\"]\n",
    "MINIO_BUCKET = response[\"bucket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TRAIN_TYPE = \"training\"\n",
    "cld_config = {\"MONITOR_NAME\":MONITOR_NAME,\n",
    "              \"INPUT_TRAIN_TYPE\":INPUT_TRAIN_TYPE, \"SERVING_DKUBE_USERNAME\":SERVING_DKUBE_USERNAME,\n",
    "              \"SERVING_DKUBE_URL\":SERVING_DKUBE_URL, \"SERVING_DKUBE_TOKEN\":SERVING_DKUBE_TOKEN, \n",
    "              \"MINIO_KEY\":MINIO_KEY,\"MINIO_SECRET_KEY\":MINIO_SECRET_KEY, \"MINIO_ENDPOINT\":MINIO_ENDPOINT,\n",
    "              \"MINIO_BUCKET\": MINIO_BUCKET,\n",
    "              \"DKUBE_BASE_DATASET\":DKUBE_BASE_DATASET, \"MODEL_NAME\":MODEL_NAME,\n",
    "              \"RUN_FREQUENCY\":RUN_FREQUENCY,\n",
    "              \"LIVE_DATASET\":LIVE_DATASET,\n",
    "              \"MONITORING_DKUBE_USERNAME\":MONITORING_DKUBE_USERNAME, \"MONITORING_DKUBE_TOKEN\":MONITORING_DKUBE_TOKEN,\n",
    "              \"MONITORING_DKUBE_URL\":MONITORING_DKUBE_URL,\n",
    "              \"SERVING_DKUBE_CLUSTER_NAME\":SERVING_DKUBE_CLUSTER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training dataset for use in the data drift comparison.  The tags field contains the project name.\n",
    "try:\n",
    "    dataset = DkubeDataset(SERVING_DKUBE_USERNAME, name=DKUBE_BASE_DATASET, tags=tags)\n",
    "    dataset.update_git_details(url=\"https://dkube-examples-data.s3.us-west-2.amazonaws.com/monitoring-insurance/training-data/insurance.csv\")\n",
    "    dataset.update_dataset_source(source=\"pub_url\")\n",
    "    serving_api.create_dataset(dataset)\n",
    "except Exception as e:\n",
    "    if e.reason.lower()!=\"conflict\":\n",
    "        response = e.body\n",
    "        print(f\"Failed[{response.code}]: {response.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for seperate monitoring cluster and adding datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MONITORING_DKUBE_URL:\n",
    "    monitoring_api = DkubeApi(URL=MONITORING_DKUBE_URL,token=MONITORING_DKUBE_TOKEN)\n",
    "    data = monitoring_api.get_modelmonitor_id(MONITOR_NAME)\n",
    "    if data.data:\n",
    "        MONITOR_ID = data.data.get(MONITOR_NAME)\n",
    "        if MONITOR_ID:\n",
    "            raise ValueError(f\"{MONITOR_NAME} monitor already existing please use a different name\")\n",
    "    try:\n",
    "        dataset = DkubeDataset(MONITORING_DKUBE_USERNAME, name=DKUBE_BASE_DATASET)\n",
    "        dataset.update_git_details(url=\"https://dkube-examples-data.s3.us-west-2.amazonaws.com/monitoring-insurance/training-data/insurance.csv\")\n",
    "        dataset.update_dataset_source(source=\"pub_url\")\n",
    "        monitoring_api.create_dataset(dataset)\n",
    "    except Exception as e:\n",
    "        if e.reason.lower()!=\"conflict\":\n",
    "            response = e.body\n",
    "            print(f\"Failed[{response.code}]: {response.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitor Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict and labelled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MONITORING_DKUBE_URL:\n",
    "    api = monitoring_api\n",
    "    user = MONITORING_DKUBE_USERNAME\n",
    "else:\n",
    "    api = serving_api\n",
    "    user = SERVING_DKUBE_USERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # If the monitor is on another cluster, do not create the live dataset within a project\n",
    "    if not SERVING_CLUSTER_EXECUTION: tags = []\n",
    "    \n",
    "    # Create the live dataset.  The tags field contains the project name\n",
    "    dataset = DkubeDataset(user, name=LIVE_DATASET,remote=True,tags=tags)\n",
    "    dataset.update_dataset_source('s3')\n",
    "    dataset.update_s3_details(\n",
    "        endpoint = MINIO_ENDPOINT,\n",
    "        bucket=MINIO_BUCKET,\n",
    "        prefix='',\n",
    "        key=MINIO_KEY,\n",
    "        secret=MINIO_SECRET_KEY)\n",
    "    api.create_dataset(dataset)\n",
    "\n",
    "except Exception as e:\n",
    "    if e.reason:\n",
    "        if e.reason.lower() != \"conflict\":\n",
    "            response = e.body\n",
    "            print(f\"Failed[{response.code}]: {response.message}\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for the deployment to come up and enabling logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del api, serving_api\n",
    "\n",
    "# Delete monitoring_api variable if it was created earlier by checking for external monitoring url being set\n",
    "if MONITORING_DKUBE_URL: del monitoring_api\n",
    "\n",
    "serving_api = DkubeApi(URL=SERVING_DKUBE_URL,token=SERVING_DKUBE_TOKEN)\n",
    "def wait_for_deployment_running(deployment_id):\n",
    "    status = None\n",
    "    inference_url, inference = None, None\n",
    "    while True:\n",
    "        data = serving_api.get_deployment(deployment_id)\n",
    "        status = data.data.inferenceservice_deployment.parameters.generated.status.state\n",
    "        inference = data.data.inferenceservice_deployment.parameters.inference\n",
    "        inference_url = data.data.inferenceservice_deployment.parameters.generated.details.serving.servingurl\n",
    "        if status == \"RUNNING\":\n",
    "            break\n",
    "        print(\"waiting for deployment to be running\")\n",
    "        time.sleep(serving_api.wait_interval)\n",
    "    return inference, inference_url\n",
    "\n",
    "while True:\n",
    "    SERVING_DEPLOYMENT_ID = serving_api.get_deployment_id(name=MONITOR_NAME)\n",
    "    if SERVING_DEPLOYMENT_ID:\n",
    "        break\n",
    "    print(\"waiting for deployment to come up\")\n",
    "    time.sleep(serving_api.wait_interval)\n",
    "inference, INFERENCE_URL = wait_for_deployment_running(SERVING_DEPLOYMENT_ID)\n",
    "if not inference.enable_logs:\n",
    "    print(\"Enabling logs\")\n",
    "    serving = DkubeServing(user=SERVING_DKUBE_USERNAME, name=MONITOR_NAME)\n",
    "    serving.update_enable_logs(enable_logs=True)\n",
    "    serving_api.update_inference(serving)\n",
    "print(\"Inference is up at URL: \", INFERENCE_URL)\n",
    "cld_config['INFERENCE_URL'] = INFERENCE_URL\n",
    "cld_config['SERVING_DEPLOYMENT_ID'] = SERVING_DEPLOYMENT_ID\n",
    "%store cld_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields Used for Setting Up Performance Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up font definitions for output\n",
    "class style:\n",
    "   RED = '\\033[91m\\033[1m'\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "# Print the instructions for the required fields for the Performance Decay setup when using UI\n",
    "print()\n",
    "print(f\"{style.BOLD}Note: These values will be needed as inputs during the Performance Decay setup in the UI creation process{style.END}\")\n",
    "print(f\"{style.RED}Live Dataset Name = {style.END}\", LIVE_DATASET)\n",
    "print(f\"{style.RED}Deployment ID (for Prefix/Subpath) = {style.END}\", SERVING_DEPLOYMENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set CLEANUP = True, after your experiment is complete.\n",
    "CLEANUP = False\n",
    "if CLEANUP:\n",
    "    serving_api.delete_dataset(SERVING_DKUBE_USERNAME,DKUBE_BASE_DATASET,force=True)\n",
    "    serving_api.delete_dataset(SERVING_DKUBE_USERNAME,LIVE_DATASET,force=True)\n",
    "    %store -d cld_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Sep 15 2022, 01:51:29) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
